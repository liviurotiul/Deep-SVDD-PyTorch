import csv
from torch.utils.data import Dataset, DataLoader
import numpy as np
from base.torchvision_dataset import TorchvisionDataset
import torchvision.transforms as transforms
from .preprocessing import get_target_label_idx
import torch
from torch.utils.data import Subset

train_samples = 90000
test_samples = 17145
all_samples = test_samples + train_samples
class MalwareDetection_Dataset(TorchvisionDataset):

    def __init__(self, root: str, normal_class=0):
        super().__init__(root)

        self.n_classes = 2  # 0: normal, 1: outlier
        self.normal_classes = tuple([normal_class])
        self.outlier_classes = [0,1]
        self.outlier_classes.remove(normal_class)

        transform = None

        target_transform = transforms.Lambda(lambda x: int(x in self.outlier_classes))

        train_set = MyMalwareDetection(root=self.root, train=True, transform=transform)

        # Subset train_set to normal class
        train_idx_normal = get_target_label_idx(train_set.train_labels.clone().data.cpu().numpy(), self.normal_classes)

        self.train_set = Subset(train_set, train_idx_normal)

        self.test_set = MyMalwareDetection(root=self.root, train=False,
                                transform=transform)

class MyMalwareDetection(Dataset):
    """Torchvision Credit Fraud class with patch of __getitem__ method to also return the index of a data sample."""

    def __init__(self, root, train, transform):

        ''' THE HOLY SAVE SCRIPT'''
        # # Path to the csv file
        # path_2_csv = "/home/liviu/Documents/Dev/Deep-SVDD-PyTorch/Datasets/malware_detection/tek_data.csv"

        # # Open and read the csv
        # with open(path_2_csv, mode='r') as infile:
        #     reader = csv.reader(infile)
        #     table = []
        #     for row in reader:
        #         table.append(list(row))

        # table = table[1:-1]        
        # table = [[float(x) for x in row] for row in table]
        # table = table[30900:-1]
        # # print(len(table))
        # table = np.asarray(table)
        # for i, _ in enumerate(table[0]):
        #     table[:,i] = table[:,i]/np.max(table[:,i])
        # np.random.shuffle(table)
        # features = table[:,1:56]
        # labels = table[:,-1]
        # # print("mean=", sum(labels/len(labels)))
        # swaped = 0

        # print(swaped, " items swaped")
        # # print(sum(labels))
        # # print(labels)
        # self.train = train
        # if self.train:
        #     number_of_ouliars = sum(labels[0:train_samples])
        #     print("=======================")
        #     print(number_of_ouliars, " out of ", train_samples, " in train split")
        #     self.train_data = torch.from_numpy(features[0:train_samples])
        #     self.train_labels = torch.from_numpy(labels[0:train_samples])

        #     number_of_ouliars = sum(labels[train_samples:all_samples])
        #     print("=======================")
        #     print(number_of_ouliars, " out of ", test_samples, " in test split")
        #     self.test_data = torch.from_numpy(features[train_samples:all_samples])
        #     self.test_labels = torch.from_numpy(labels[train_samples:all_samples])
            
        # else:
        #     number_of_ouliars = sum(labels[train_samples:all_samples])
        #     print("=======================")
        #     print(number_of_ouliars, " out of ", test_samples, " in test split")
        #     self.test_data = torch.from_numpy(features[train_samples:all_samples])
        #     self.test_labels = torch.from_numpy(labels[train_samples:all_samples])

        # torch.save(self.test_data, 'test_data.pt')
        # torch.save(self.test_labels, 'test_labels.pt')
        # torch.save(self.train_labels, 'train_labels.pt')
        # torch.save(self.train_data, 'train_data.pt')
        # self.transform = transform

        # import pdb; pdb.set_trace()
        self.train = train
        if self.train:
            self.train_data = torch.load('train_data.pt')
            self.train_labels = torch.load('train_labels.pt')
        else:
            self.test_data = torch.load('test_data.pt')
            self.test_labels = torch.load('test_labels.pt')
   
        self.transform = transform

    def __getitem__(self, index):

        if self.train:
            features, target = self.train_data[index], self.train_labels[index]
        else:
            features, target = self.test_data[index], self.test_labels[index]


        if self.transform:
            return self.transform(features), self.transform(target), index
        else:
            return features, target, index
    
    def __len__(self):

        if self.train:
            return len(self.train_data)
        return len(self.test_data)
